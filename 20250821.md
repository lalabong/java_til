
# 쿠버네티스

요즘 클라우드 네이티브 개발을 하다 보면 피할 수 없는 기술이 바로 **쿠버네티스**입니다. 처음 들어보면 "또 다른 복잡한 기술이구나" 싶겠지만, 실제로는 복잡한 인프라 문제들을 정말 우아하게 해결해주는 놀라운 도구예요. 마치 수백 명의 오케스트라를 지휘하는 지휘자처럼 말이죠.

## 쿠버네티스가 해결하려는 근본적인 문제

### Docker의 한계를 넘어서

Docker가 컨테이너 기술을 대중화시켰지만, 실제 운영 환경에서는 **하나의 서버에서만 컨테이너를 관리하는 것으로는 부족**합니다. 현실의 서비스는 수십, 수백 개의 컨테이너가 여러 서버에 분산되어 돌아가거든요.

```
기존 문제들:
- 컨테이너가 죽으면 누가 다시 켜줄까?
- 트래픽이 몰리면 컨테이너를 어떻게 자동으로 늘릴까?
- 여러 서버에 걸쳐 있는 컨테이너들이 어떻게 서로 찾아갈까?
- 업데이트할 때 서비스 중단 없이 어떻게 배포할까?
- 서버 하나가 죽으면 그 위의 컨테이너들은 어디로 갈까?
```

쿠버네티스는 이 모든 문제를 **"원하는 상태를 선언하면 알아서 그 상태를 유지해준다"** 는 철학으로 해결합니다.

## 쿠버네티스의 핵심 개념들

### 클러스터: 모든 것의 시작점

**클러스터**는 쿠버네티스가 관리하는 서버들의 집합입니다. 마치 여러 대의 컴퓨터를 묶어서 하나의 거대한 컴퓨터처럼 사용할 수 있게 해주는 거예요.

```
클러스터 구성:
마스터 노드 (Control Plane) - 전체를 관리하는 두뇌
워커 노드들 - 실제 컨테이너가 실행되는 일꾼들
```


### Pod: 쿠버네티스의 최소 단위

**Pod(포드)** 는 쿠버네티스에서 배포할 수 있는 가장 작은 단위입니다. 하나 이상의 컨테이너를 담고 있는 그릇이라고 생각하면 됩니다.

```yaml
# 간단한 Pod 예시
apiVersion: v1
kind: Pod
metadata:
  name: my-app-pod
  labels:
    app: my-app
spec:
  containers:
  - name: web-server
    image: nginx:1.20
    ports:
    - containerPort: 80
  - name: log-collector
    image: fluentd:latest
    # 같은 Pod 안의 컨테이너들은 IP를 공유
```


### Deployment: 실전에서 사용하는 배포 단위

실제로는 Pod를 직접 만들지 않고 **Deployment**를 사용합니다. 이게 진짜 실무에서 중요한 개념이에요.

```yaml
# Production급 배포 설정
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-web-app
spec:
  replicas: 3  # 동일한 Pod를 3개 띄워라
  selector:
    matchLabels:
      app: my-web-app
  template:
    metadata:
      labels:
        app: my-web-app
    spec:
      containers:
      - name: web
        image: my-web-app:v1.2.0
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
```


### Service: 네트워킹의 마법사

Pod들은 생성되고 사라질 때마다 IP가 바뀝니다. **Service**는 이런 동적인 환경에서도 안정적으로 통신할 수 있게 해주는 네트워킹 추상화 계층입니다.

```yaml
# LoadBalancer 타입 Service
apiVersion: v1
kind: Service
metadata:
  name: my-web-service
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
  selector:
    app: my-web-app  # 이 라벨을 가진 Pod들로 트래픽 분산
```

이렇게 설정하면 클라우드 제공업체(AWS, GCP, Azure)가 자동으로 로드밸런서를 만들어주고, 외부에서 접속할 수 있는 고정 IP를 제공해줍니다.

## 실무에서의 쿠버네티스 활용

### 자동 스케일링: 트래픽에 따른 유연한 대응

쿠버네티스의 가장 강력한 기능 중 하나가 **HPA(Horizontal Pod Autoscaler)** 입니다. 트래픽이 몰리면 자동으로 Pod 개수를 늘리고, 줄어들면 다시 줄여줍니다.

```yaml
# 자동 스케일링 설정
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-web-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # CPU 사용률이 70% 넘으면 스케일 아웃
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # 메모리 사용률 80% 기준
```


### 무중단 배포: Rolling Update

새 버전을 배포할 때 서비스 중단 없이 점진적으로 교체하는 **Rolling Update**가 기본으로 지원됩니다.

```yaml
# 배포 전략 설정
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1      # 최대 1개까지 중단 허용
      maxSurge: 2            # 최대 2개까지 추가 생성 허용
  template:
    spec:
      containers:
      - name: app
        image: my-app:v2.0.0  # 새 버전으로 업데이트
```

이렇게 설정하면 쿠버네티스가 알아서 하나씩 새 버전으로 교체하면서 서비스는 계속 살아있게 해줍니다.

### ConfigMap과 Secret: 설정 관리의 베스트 프랙티스

**ConfigMap**으로 애플리케이션 설정을, **Secret**으로 민감한 정보를 관리합니다.

```yaml
# 설정 정보 분리
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database.host: "prod-db.company.com"
  database.port: "5432"
  log.level: "INFO"
  feature.flag: "true"

---
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  database.password: cGFzc3dvcmQxMjM=  # base64 인코딩
  api.key: YWJjZGVmZ2hpams=

---
# Deployment에서 사용
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    spec:
      containers:
      - name: app
        image: my-app:latest
        env:
        - name: DB_HOST
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: database.host
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database.password
```


## 쿠버네티스 vs 다른 오케스트레이션 도구

### Docker Swarm과의 비교

**Docker Swarm**은 간단하지만 기능이 제한적이에요. 소규모 프로젝트나 학습용으로는 좋지만, 복잡한 운영 환경에서는 쿠버네티스가 압도적으로 유리합니다.

```
Docker Swarm: 간단함, 학습 곡선 낮음, 기능 제한적
Kubernetes: 복잡함, 학습 곡선 높음, 기능 강력함, 생태계 풍부
```


### 클라우드 서비스와의 관계

각 클라우드 제공업체는 관리형 쿠버네티스 서비스를 제공합니다:

```
AWS: EKS (Elastic Kubernetes Service)
Google Cloud: GKE (Google Kubernetes Engine)
Azure: AKS (Azure Kubernetes Service)
```

이런 관리형 서비스를 사용하면 쿠버네티스 클러스터 관리의 복잡함을 크게 줄일 수 있어요.

## 실제 배포 시나리오

### Spring Boot 마이크로서비스 배포

실무에서 가장 흔한 패턴인 Spring Boot 애플리케이션 배포를 예로 들어볼게요:

```yaml
# 완전한 마이크로서비스 배포 예시
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  labels:
    service: user-service
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
        service: user-service
        version: v1
    spec:
      containers:
      - name: user-service
        image: mycompany/user-service:1.5.2
        ports:
        - containerPort: 8080
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "production"
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 45
          periodSeconds: 20
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8080
  selector:
    app: user-service
```


### CI/CD와의 통합

GitLab CI나 GitHub Actions에서 쿠버네티스로 자동 배포하는 파이프라인:

```yaml
# .github/workflows/deploy.yml
name: Deploy to Kubernetes
on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up kubectl
      uses: azure/k8s-set-context@v1
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG }}
    
    - name: Deploy to cluster
      run: |
        # 이미지 태그 업데이트
        kubectl set image deployment/user-service \
          user-service=mycompany/user-service:${{ github.sha }}
        
        # 롤아웃 상태 확인
        kubectl rollout status deployment/user-service
        
        # 배포 결과 확인
        kubectl get pods -l app=user-service
```


## 모니터링과 로깅

### Prometheus와 Grafana 연동

쿠버네티스 환경에서는 **Prometheus + Grafana** 조합이 거의 표준입니다:

```yaml
# 애플리케이션 메트릭 노출
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    metadata:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/actuator/prometheus"
    spec:
      containers:
      - name: app
        image: my-app:latest
        ports:
        - containerPort: 8080
          name: http-metrics
```


### 중앙화된 로깅

**ELK Stack** (Elasticsearch, Logstash, Kibana)이나 **EFK Stack** (Fluentd 사용)으로 로그를 중앙화:

```yaml
# Fluentd DaemonSet으로 모든 노드의 로그 수집
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
```


## 학습 로드맵과 실무 팁

### 단계별 학습 가이드

**1단계: 기본 개념 이해**

- Docker 컨테이너 기술 숙지
- Pod, Deployment, Service 개념
- kubectl 기본 명령어 학습

**2단계: 로컬 환경 구축**

```bash
# minikube로 로컬 클러스터 구축
minikube start
kubectl get nodes

# 간단한 애플리케이션 배포 연습
kubectl create deployment hello-world --image=nginx
kubectl expose deployment hello-world --port=80 --type=LoadBalancer
```

**3단계: 실전 프로젝트**

- YAML 매니페스트 작성 연습
- CI/CD 파이프라인 구축
- 모니터링 도구 연동


### 실무에서의 주의사항

**리소스 제한 설정은 필수**입니다. 설정하지 않으면 하나의 Pod가 전체 노드 리소스를 독점할 수 있어요:

```yaml
resources:
  requests:
    memory: "256Mi"    # 최소한 필요한 메모리
    cpu: "250m"        # 최소한 필요한 CPU (0.25 코어)
  limits:
    memory: "512Mi"    # 최대 사용 가능한 메모리
    cpu: "500m"        # 최대 사용 가능한 CPU (0.5 코어)
```

**네임스페이스로 환경 분리**도 중요합니다:

```bash
# 환경별 네임스페이스 생성
kubectl create namespace development
kubectl create namespace staging  
kubectl create namespace production

# 특정 네임스페이스에 배포
kubectl apply -f deployment.yaml -n production
```


## 마무리

쿠버네티스는 단순한 도구를 넘어서 **현대 소프트웨어 아키텍처의 표준**이 되었습니다. 클라우드 네이티브, 마이크로서비스, DevOps, 이 모든 것들이 쿠버네티스를 중심으로 돌아가고 있어요.

처음에는 복잡해 보이지만, 한 번 익숙해지면 **"쿠버네티스 없이 어떻게 서비스를 운영했을까?"** 싶을 정도로 강력한 도구입니다. 특히 요즘처럼 서비스가 글로벌화되고 트래픽이 예측 불가능한 시대에, 자동 스케일링과 무중단 배포는 거의 필수 기능이 되었거든요.

가장 중요한 건 **작은 것부터 시작하는 것**입니다. minikube로 로컬에서 간단한 애플리케이션을 배포해보고, 점점 복잡한 기능들을 하나씩 추가해보세요. 어느 순간 쿠버네티스가 여러분의 인프라 고민을 모두 해결해주는 든든한 파트너가 되어있을 거예요.
